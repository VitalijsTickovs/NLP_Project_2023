{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:07:46.832498Z",
     "end_time": "2023-05-26T12:07:47.244445Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "products = pd.read_csv('products_train.csv')\n",
    "unique_locales = products['locale'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:07:47.245404Z",
     "end_time": "2023-05-26T12:07:54.872063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['DE', 'JP', 'ES', 'FR', 'IT'], dtype=object)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LOCALES TO TRANSLATE\n",
    "unique_locales = np.delete(unique_locales, np.where(unique_locales == 'UK'))\n",
    "unique_locales"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:07:54.871579Z",
     "end_time": "2023-05-26T12:07:54.875253Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# German Machine Translation\n",
    "\n",
    "reference: [English To German Model](https://huggingface.co/google/bert2bert_L-24_wmt_de_en)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/bert2bert_L-24_wmt_de_en\", pad_token=\"<pad>\", eos_token=\"</s>\", bos_token=\"<s>\", unk_token=\"<unk>\", max_length=128)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/bert2bert_L-24_wmt_de_en\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:07:54.875565Z",
     "end_time": "2023-05-26T12:08:16.742146Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (128) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Want to drink a как go with me?\n"
     ]
    }
   ],
   "source": [
    "## SILLY EXAMPLE, CAN PLAY WITH THIS IF YOU WANT :)\n",
    "sentence = \"Willst du einen как trinken gehen mit mir?\"\n",
    "\n",
    "input_ids = tokenizer(sentence, return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "output_ids = model.generate(input_ids)[0]\n",
    "print(tokenizer.decode(output_ids, skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T11:43:18.811548Z",
     "end_time": "2023-05-26T11:43:29.968505Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real fun part"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    import re    # for regular expressions\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)\n",
    "        text = re.sub(r'[^\\w\\s]', \"\", text)\n",
    "        text = re.sub(r'[^\\w\\d\\s]', '', text)\n",
    "        ## THE TEXT CONTAINED THE SAME GARBAGE AS IN ENGLISH TITLES\n",
    "        ## SHIT DATASET\n",
    "        # I HATE LIFE\n",
    "        text = re.findall(r'\\b(?:[a-zA-Z]+|\\d+)\\b', text)\n",
    "        text = \" \".join(text)\n",
    "        # removing non-unicode characters\n",
    "        # for example, it will remove character 'Ç'\n",
    "        non_ascii_pattern = re.compile(r'[^\\x00-\\x7F]+')\n",
    "        text = non_ascii_pattern.sub('', text)\n",
    "\n",
    "        # Tokenize it\n",
    "        return text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "    # Return a string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:08:16.722958Z",
     "end_time": "2023-05-26T12:08:16.751013Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518327\n"
     ]
    },
    {
     "data": {
      "text/plain": "0          RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...\n1          Simply Keto Lower Carb* Schokodrops ohne Zucke...\n2          Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...\n3          AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...\n4              PLAYMOBIL - 70522 - Cavaliere mit grauem Pony\n                                 ...                        \n1551052    Barbie - Playset Gelateria con Bambola con Mac...\n1551053    Braun Silk-épil 1 Depilatore Donna, Epilatore ...\n1551054    BoxLegend Sacchetti Sottovuoto Vestiti 6 Pezzi...\n1551055    Trasportino Pratiko Metal - Accessorio da viag...\n1551056    LiCB - Batterie LR1130, batterie alcaline AG10...\nName: title, Length: 1551049, dtype: object"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get all the german rows\n",
    "locale = 'DE'\n",
    "de_products = products.loc[products['locale'] == locale]\n",
    "print(len(de_products))\n",
    "# Get only titles\n",
    "de_products_title = products['title']\n",
    "# drop all nan rows\n",
    "de_products_title.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:08:16.724998Z",
     "end_time": "2023-05-26T12:08:18.305799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# a bit of preprocessing\n",
    "# will update it\n",
    "de_products_title = de_products_title.apply(process)\n",
    "# converting to list to translate the rows\n",
    "de_products_title_list = de_products_title.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:08:18.304793Z",
     "end_time": "2023-05-26T12:08:35.690248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "### DUMB DEBUGGER\n",
    "\n",
    "## REAL FUN\n",
    "## NOT FUN ACTUALLY\n",
    "# decoded_sequences = []\n",
    "# for i in range(161+102, len(de_products_title_list)):\n",
    "#     input_ids = tokenizer(de_products_title_list[i], padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=False).input_ids\n",
    "#     output_ids = model.generate(input_ids)[0]\n",
    "#     decoded_sequences.append(tokenizer.decode(output_ids, skip_special_tokens=True))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:08:35.689044Z",
     "end_time": "2023-05-26T12:08:35.691377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (128) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished batch:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "## REAL REAL FUN\n",
    "## CHECK OUTPUT :)\n",
    "batch_size = 20\n",
    "decoded_sequences = pd.DataFrame(columns=['title'])\n",
    "\n",
    "for i in range(0,math.floor(len(de_products_title_list)/batch_size), batch_size):\n",
    "    input_ids = tokenizer.batch_encode_plus(de_products_title_list[i:i+batch_size], padding = True,return_tensors=\"pt\")['input_ids']\n",
    "    output_ids = model.generate(input_ids)\n",
    "    decoded_batch = {'title':tokenizer.batch_decode(output_ids, skip_special_tokens = True)}\n",
    "    decoded_sequences = pd.concat([decoded_sequences, pd.DataFrame(decoded_batch)], ignore_index=True)\n",
    "    print(\"Finished batch: \", i)\n",
    "print(decoded_sequences.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-26T12:12:03.290053Z",
     "end_time": "2023-05-26T12:14:04.610054Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoded_sequences.to_csv('german-to-english.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
